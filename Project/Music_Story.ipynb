{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Our helpers\n",
    "from map_helpers import *\n",
    "from data_helpers import *\n",
    "from helpers import *\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, PCA\n",
    "\n",
    "import json\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "#Plot data\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better vizualisation of this notebook please read it using the [notebook viewer](https://nbviewer.jupyter.org/github/cgallay/Ada/blob/master/Project/Projet_ADA_M2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the million song Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the web site :  https://labrosa.ee.columbia.edu/millionsong \"The Million Song Dataset is a freely-available collection of audio features and metadata for a million contemporary popular music tracks.\n",
    "The core of the dataset is the feature analysis and metadata for one million songs, provided by The Echo Nest. The dataset does not include any audio, only the derived features.\"\n",
    "\n",
    "The entire dataset size is 280 GB. We however, based our final analysis on a subset of roughly 100,000 songs. We decided not tu use spark as we could manage a third of the dataset with standard methods and was a sufficiant size for our analysis.\n",
    "\n",
    "You will see below the first steps of our approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features description : \n",
    "The list of the 54 features present in the dataset, can be found here : https://labrosa.ee.columbia.edu/millionsong/pages/example-track-description\n",
    "In order not to list them all we choose here to describe the one that seems reelevent to our project: \n",
    "\n",
    " * **artist_name** \n",
    " * **artist latitude:**\tfloat\tlatitude\n",
    " * **artist longitude:** float\tlongitude\n",
    " * **artist_terms:** tags from The Echo Nest in float with range : [0:1]\n",
    " * **artist_terms_freq:** similar to mbtags_count but from Echo Nest in float with range : [0:1]  \n",
    " * **artist_terms_weight:** same shape as the two previous tags in float with range : [0:1]\n",
    " * **loudness:** the overall loudness of a track in decibels (dB). Loudness values in the Analyzer are averaged across an entire track and are useful for comparing relative loudness of segments and tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude).\n",
    " * **song_hotttnesss:** according to The Echo Nest, when downloaded (in December 2010) in float with range [0:1]\n",
    " * **segments_pitches** The key is a track-level attribute with range : [0:11] and corresponding to one of the 12 keys: C, C#, D, etc. up to B. If no key was detected, the value is -1. The mode is equal to 0 or 1 for “minor” or “major” and may be -1 in case of no result.\n",
    " * **segments_timbre** timbre is the quality of a musical note or sound that distinguishes different types of musical instruments, or voices. It is a complex notion also referred to as sound color, texture, or tone quality, and is derived from the shape of a segment’s spectro-temporal surface, independently of pitch and loudness.\n",
    " * **tempo:** tempo in BPM according to The Echo Nest\n",
    " * **title**\n",
    " * **year:** when this song was released, according to musicbrainz.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data\n",
    "We proceded in two steps:\n",
    "\n",
    "- Firtly, we loaded the dataset by batches and, for each of them, we extracted the useful features. We saved all the data in pickle formats for faster loading.\n",
    "\n",
    "- Secondly, we loaded the corresponding pickles according to our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating all pickles (WARNING: Takes ~2 Hours)\n",
    "for letter in ['A', 'B', 'C', 'D', 'E', 'F']:\n",
    "    for half in [1, 2]:\n",
    "        df = load_song_data(letter, half)\n",
    "        df1 = select_col(filter_year(df), part=1).dropna()\n",
    "        df2 = select_col(exctract_timbre_features(filter_hotness(df, 0.001)), part=2).dropna()\n",
    "        save_pickle_filtered(df1, letter, part=1, half=half)\n",
    "        save_pickle_filtered(df2, letter, part=2, half=half)\n",
    "        del df, df1, df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Discovering Genre through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the corresponding subdataset for the first part\n",
    "df_song = merge_pickles(['A', 'B', 'C', 'D', 'E', 'F'], 2)\n",
    "df_song = df_song.sort_values('song_hotttnesss', ascending=False)\n",
    "df_song = df_song.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_deezer = add_previews_deezer(df_song[:30000], './pickle_data/complete_song_previews_url_Deezer_ABCDEF_0-30000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_spotify = add_previews_spotify(df_song[:30000], './pickle_data/complete_song_previews_url_spotify_ABCDEF_0-30000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = complete_previews(df_deezer, df_spotify, './pickle_data/complete_song_previews_url_completed_ABCDEF_0-30000.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
